<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SeeShell</title>
    <link rel="stylesheet" href="../css/style.css">
</head>
<body>
<header>
    <h1>SeeShell</h1>
</header>

<div class="sidebar">
    <a href="#overview">Project Overview</a>
    <a href="#implementation">Implementation Details</a>
    <a href="#visuals">Visuals & Support</a>
    <hr> <!-- Separator line -->
    <a href="../index.html">Back to Home</a>
</div>

<div class="main-content">
    <!-- Top Container with Image and Text -->
    <div class="top-container">
        <img src="../images/Logo.jpg" alt="SeeShell App Image"> 
        <div class="text-content">
            <h2>About SeeShell</h2>
            <p>SeeShell is a mobile app that enhances shell collecting by using image recognition to identify shell species. 
            It provides educational information about the shells' stories, evolution, and origins. The app appeals to beachgoers 
            and collectors, allowing them to manage digital collections. SeeShell offers an engaging experience for those interested 
            in exploring the ocean's mysteries while beachcombing.</p>
        </div>
    </div>

    <section id="overview">
        <h2>Project Overview</h2>
        <p>During the Spring semester of 2023, I had the privilege of collaborating with Alexander Johnson, Eron Neill, Leah Schneidereit, 
            Ahmed Elgazar, and Thomas Smith on an exciting full-stack application project we named 'SeeShell'. As part of the Software Engineering 
            (CSC 550) course at UNCW, our goal was to develop a functional software system while achieving the learning objectives for the course. 
            Our project involved developing SeeShell, an application that uses machine learning to match and identify seashells from user-captured 
            images. Our goal was to create a user-friendly tool for shell collectors, providing a seamless experience for shell identification and 
            learning. We worked diligently to achieve project milestones within the specified deadline of May 4th, 2023.</p>


        <h3>Project Description</h3>
        <p>Experience the ultimate beachcombing adventure with SeeShell, a mobile app that transforms shell collecting. Simply snap a photo or 
            upload an image of a seashell, and our advanced image recognition technology instantly identifies its species from a comprehensive 
            database. Dive into the captivating world of shells, manage your digital collection effortlessly, and embark on an interactive and 
            educational journey along the shoreline.</p>

        <h3>Scope</h3>
        <p>The scope of the SeeShell project entailed developing a mobile application that enhanced the shell collecting experience for beachgoers 
            and avid shell collectors. The application allowed users to capture photos of shells and utilized a machine learning algorithm for 
            species identification. Upon identification, the app provided educational content about the specific shell species, including its 
            evolutionary history and origin. Users had the ability to manage a digital collection of their found shells within the app. To ensure 
            accessibility and convenience, the app supported offline functionality, enabling users to upload shell images even without an internet 
            connection. The project was delivered within a 16-week timeline, with the initial release focused on delivering basic functionality, 
            while future work was considered for implementing more advanced features. Our team prioritized the development of critical features to 
            ensure a valuable and robust mobile application for users.</p>

        <h3>Features</h3>
        <ul>
            <li><strong>Image Capture and Recognition:</strong> The app will enable users to capture photos or upload images of shells using their 
                phone camera. Leveraging image recognition technology, the app will match the shell to a species from a comprehensive database.</li>
            <li><strong>Image Saving:</strong> Matched shell images will be automatically saved to a digital collection within the app. Users will 
                have the ability to view their collection and access species information at any time.</li>
            <li><strong>Account Management:</strong> The app will provide users with the option to create an account or log into an existing account. 
                This feature ensures that their digital collection information remains accessible and up to date.</li>
            <li><strong>Digital Collection Management:</strong> Users will have the ability to manage their digital collection of shell photos within 
                the app. This includes features such as adding titles to images and deleting unwanted photos from the collection.</li>
        </ul>

        <h3>Functionalities</h3>
        <ul>
            <li><strong>Image Capture and Recognition:</strong>
                <ul>
                    <li>Capture a photo of a shell using the phone camera.</li>
                    <li>Upload an image of a shell from the phone gallery.</li>
                    <li>Utilize image recognition technology to match the shell to a species from a database.</li>
                    <li>Display the best match of the shell species and provide information about the shell.</li>
                </ul>
            </li>
            <li><strong>Account Management:</strong>
                <ul>
                    <li>Allow users to create an account with credentials.</li>
                    <li>Enable users to log in to their accounts.</li>
                    <li>Maintain user authentication data in the database.</li>
                    <li>Provide access to the app and user-specific information upon successful authentication.</li>
                </ul>
            </li>
            <li><strong>Digital Collection Management:</strong>
                <ul>
                    <li>Automatically save captured shell images.</li>
                    <li>Save species information and shell photos locally.</li>
                    <li>Allow users to view their digital collection of shells.</li>
                    <li>Enable users to delete images from their digital collection.</li>
                    <li>Allow users to add a title/location to the image (future work).</li>
                </ul>
            </li>
        </ul>
    </section>

    <section id="implementation">
        <h2>Implementation Details</h2>
        <h3>Technologies Used</h3>
        <h4>Programming Languages</h4>
        <ul>
            <li>Python: The entire client-server architecture was built using Python.</li>
        </ul>
        <h4>Client-Side Technologies</h4>
        <ul>
            <li>Kivy: A cross-platform Python framework used for creating the user interface on Android devices and other platforms.</li>
            <li>KivyMD: A library that provides Material Design components and styling for Kivy applications.</li>
            <li>Camera4kivy: A library used to access the device's camera functionality.</li>
            <li>Plyer: A library used to access various hardware and built-in functionalities of the device.</li>
            <li>Pyjnius: A Python library that allows interaction with Java code, used for accessing device features.</li>
            <li>Requests: A library used for sending data from the client to the server.</li>
            <li>Apscheduler: A library used for scheduling and executing periodic tasks in the background of the client app.</li>
        </ul>
        <h4>Server-Side Technologies</h4>
        <ul>
            <li>Flask: A Python web framework used to create the server-side API.</li>
            <li>SQLAlchemy: A Python SQL toolkit and Object-Relational Mapping (ORM) system used for efficient connectivity to the MySQL database.</li>
            <li>PyMySQL: A Python library used for secure connectivity to the MySQL database.</li>
            <li>TensorFlow: A machine learning framework used for training and deploying the machine learning models.</li>
            <li>Matplotlib: A plotting library used for data visualization in the server-side components.</li>
            <li>IBM Watson Machine Learning: Used for hosting and inference of the trained machine learning model.</li>
            <li>Bcrypt: A library used for password encryption.</li>
            <li>Cryptography: A library used for cryptographic operations.</li>
            <li>JSON and SimpleJSON: Libraries used for handling JSON data.</li>
        </ul>
        <h4>Version Control and Collaboration</h4>
        <ul>
            <li>GitHub: Used for version control of the project.</li>
        </ul>
        <h4>Communication and Collaboration Tools</h4>
        <ul>
            <li>Slack: Used for team communication.</li>
            <li>Zoom: Used for meetings and video conferences.</li>
        </ul>
        <h4>Documentation and Office Tools</h4>
        <ul>
            <li>Microsoft Office: Used for documentation and office-related tasks.</li>
        </ul>
        <h4>Team Coordination and Scheduling</h4>
        <ul>
            <li>When2meet: Used for coordinating team member availability.</li>
        </ul>
        <h4>File Sharing and Storage</h4>
        <ul>
            <li>OneDrive: Used for file sharing and collaboration.</li>
        </ul>
        <h4>External Integrations</h4>
        <ul>
            <li>MolluscaBase: An API used for bulk data download.</li>
            <li>IBM Watson: Used for hosting the trained classifier model and performing inference.</li>
            <li>University of Macau: Used for the shell image dataset.</li>
        </ul>
        <h4>Additional Tools</h4>
        <ul>
            <li>Android Studio: Used for Android app testing and emulation.</li>
        </ul>
    </section>

    <section id="visuals">
        <h2>Visuals & Support</h2>
        <h3>Front End User Interface</h3>
        <div class="image-gallery">
        <p><img src="../images/front end-login screen.png" alt="Front End - Login Screen"></p>
        <p><img src="../images/front end-capture screen.png" alt="Front End - Capture Screen"></p>
        <p><img src="../images/front end-gallery screen.png" alt="Front End - Gallery Screen"></p>
        </div>
        <h3>My Role</h3>
        <ul>
            <li>Logo Creation</li>
            <li>Front-End Development</li>
            <li>Documentation</li>
        </ul>
        <h3>Results</h3>
        <p>We successfully developed a functional and scalable system as our end result.</p>
        <h3>Project Duration and Team Size</h3>
        <p>In our group, consisting of six members, including myself, we embarked on a 16-week project duration. In total, our group spent 468 
            hours to complete the project. Utilizing the agile methodology, we crafted a comprehensive plan that outlined the sprints and their 
            corresponding activities throughout the project timeline. This approach aimed to foster flexibility while maintaining the essential 
            structure required to effectively manage the software project's scope and timeline.</p>
            
        <h3>Project Repository</h3>
        <div class="file-links">
            <a href="https://github.com/eyneill777/SeeShell.git" target="_blank">SeeShell Repository</a>
        </div>
        <h3>Project Documentation</h3>
        <div class="file-links">
            <a href="https://github.com/eyneill777/SeeShell/tree/main/Documentation" target="_blank">SeeShell Code Documentation</a>
        </div>
        <h3>Report</h3>
        <div class="file-links">
            <a href="../files/seeshell_project.pdf" target="_blank">SeeShell Report</a>
        </div>
    </section>
</div>

<footer>
    <p>Contact: <a href="mailto:michaelaann907@gmail.com">michaelaann907@gmail.com</a> | Phone: <a href="tel:+19109772489">910-977-2489</a></p>
</footer>

<script src="../js/script.js"></script>

</body>
</html>
